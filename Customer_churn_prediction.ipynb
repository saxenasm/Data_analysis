{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting customer churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('churn_dataset_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 20 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   state                          3500 non-null   object \n",
      " 1   account_length                 3500 non-null   int64  \n",
      " 2   area_code                      3500 non-null   object \n",
      " 3   international_plan             3500 non-null   object \n",
      " 4   voice_mail_plan                3500 non-null   object \n",
      " 5   number_vmail_messages          3500 non-null   int64  \n",
      " 6   total_day_minutes              3500 non-null   float64\n",
      " 7   total_day_calls                3500 non-null   int64  \n",
      " 8   total_day_charge               3216 non-null   float64\n",
      " 9   total_eve_minutes              3500 non-null   float64\n",
      " 10  total_eve_calls                3269 non-null   float64\n",
      " 11  total_eve_charge               3500 non-null   float64\n",
      " 12  total_night_minutes            3500 non-null   float64\n",
      " 13  total_night_calls              3500 non-null   int64  \n",
      " 14  total_night_charge             3500 non-null   float64\n",
      " 15  total_intl_minutes             3500 non-null   float64\n",
      " 16  total_intl_calls               3500 non-null   int64  \n",
      " 17  total_intl_charge              3500 non-null   float64\n",
      " 18  number_customer_service_calls  3500 non-null   int64  \n",
      " 19  churn                          3500 non-null   object \n",
      "dtypes: float64(9), int64(6), object(5)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"total_day_charge\" and  \"total_eve_calls\" have NA values ,we will impute them with 0 for this excercise,we can fgure better ways of imputing them later if they emerge as important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encoding the binary variables for modeling purposes\n",
    "\"\"\"\n",
    "df['churn_coded']=np.where(df.churn=='yes',1,0)\n",
    "df['int_plan_coded']=np.where(df.international_plan=='yes',1,0)\n",
    "df['vm_plan_coded']=np.where(df.voice_mail_plan=='yes',1,0)\n",
    "df['churn_coded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 column1             column2  correlation\n",
      "0  number_vmail_messages       vm_plan_coded         0.95\n",
      "1    total_night_minutes  total_night_charge         1.00\n"
     ]
    }
   ],
   "source": [
    "t=df.corr()\n",
    "col_list=t.columns\n",
    "d= pd.DataFrame(columns=['column1','column2', 'correlation'])\n",
    "i=0\n",
    "for col in col_list[0: int(len(col_list)/2)]:\n",
    "    for col1 in col_list[int(len(col_list)/2):]:\n",
    "        if col!=col1:\n",
    "            corr=round(t.iloc[t.index==col][col1].values[0] ,2)\n",
    "            if(abs(corr)>0.3):\n",
    "                d=d.append(dict(zip( ['column1','column2', 'correlation'],\n",
    "                                 [col,col1, corr])) , True)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no unexpected correlations in the data, however among the expected ones-\n",
    "1. There is significant correlation between 'number_vmail_messages' and 'vm_plan_coded' , which means if there is an active voicemail plan for customer he has non zero voicemail messages.\n",
    "2. Also 'total_night_minutes' is positive highly corleated with 'total_night_charge' which is obvious as \n",
    "   charge= minutes*rate\n",
    "   \n",
    "Conclusion- We can eliminate one of the variables for modeling purposes as they convey same information/variance.  I elinimiate 'total_night_charge' as it is a dervied varibale,  and 'vm_plan_coded' as it is encoded variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.860857\n",
       "yes    0.139143\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.churn.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is class imbalance , class 1,as in churn= yes is minorty class meaning 13% customers are likely to leave the company and nt continue with their plan, and 86% customers are retained over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shuffling the data before train test split\n",
    "\"\"\"\n",
    "df=df.sample(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols=['account_length', \n",
    "       'number_vmail_messages', 'total_day_minutes',\n",
    "       'total_day_calls', 'total_day_charge', 'total_eve_minutes',\n",
    "       'total_eve_calls', 'total_eve_charge', 'total_night_minutes',\n",
    "       'total_night_calls','total_intl_minutes',\n",
    "       'total_intl_calls', 'total_intl_charge',\n",
    "       'number_customer_service_calls', \n",
    "       'int_plan_coded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM - boosting based method for churn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8895238095238095"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\"\"\"\n",
    "Train test split 70/30\n",
    "\"\"\"\n",
    "idx= int(0.7*df.shape[0])\n",
    "X_train, y_train= df[train_cols][0:idx] ,  df['churn_coded'][0:idx]\n",
    "X_test, y_test= df[train_cols][idx:] ,  df['churn_coded'][idx:]\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "  max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob=clf.predict_proba(X_test)\n",
    "pred= np.where(pred_prob>0.5 , 1,0)\n",
    "y_pred= [np.argmax(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    907\n",
       "1    143\n",
       "Name: churn_coded, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "distribution of target variable in test data, to ensure that model doesn't make a blind guess\n",
    "and predict everything as majority class.\n",
    "\n",
    "\"\"\"\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[873,  34],\n",
       "       [ 82,  61]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7251532191824098"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recall for actual churn='yes'/1 cases is 43% --> 61(TP) out of 143 churn cases in test data, considering that it is moinority class being able to classify 43% of churn cases is still okay to begin with. \n",
    "We can use oversampling method to increase the recall as in supply more churn cases to train data so as it learn its patterns.\n",
    "\n",
    "However precision for churn class is only 61/(61+34)= 64% which is concerning , 64 out of 100 cases that model predicts as churn cases are actual churn cases, company will be wasting its resources on giving promotions to rest 37% customers who might not actually churn but the model says so.\n",
    "\n",
    "Derterming the performace of this model will be a function of company's spend on a false positive case vs loss on False negative case, as in how much it costs to retain a churn case by giving them promotions (false positive case) and how much it costs the company to lose a customer (False negative).\n",
    "\n",
    "Overall the model needs lot of improvement to be useful to buisness\n",
    "\n",
    "F1 score of model is 72% and a good F1 score means that you have low false positives and low false negatives,f1 score in our case is decent to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying random forest model - bagging based model for churn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9085714285714286"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[904,   3],\n",
       "       [ 93,  50]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob=clf.predict_proba(X_test)\n",
    "pred= np.where(pred_prob>0.5 , 1,0)\n",
    "y_pred= [np.argmax(x) for x in pred]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7298919567827131"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precsion = 50/53= 94%\n",
    "recall = 50/143=34%\n",
    "A bagging model gives 94% precsion on churn class as it will be correct 94% time when it says that a customer is likely to churn.\n",
    "However its recall is 34% lower than boosting model , which means of the 143 cases that actually churn it is able to correctly predict 34% of them.\n",
    "Advantage of this bagging model over boosting is that has less False positives 3 vs 34.\n",
    "The boosting model had less False negatives 93 vs 82.\n",
    "\n",
    "F1 score of model is 72% and a good F1 score means that you have low false positives and low false negatives,f1 score in our case is decent to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>feature_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_day_minutes</td>\n",
       "      <td>0.231654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_day_charge</td>\n",
       "      <td>0.168910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>int_plan_coded</td>\n",
       "      <td>0.134480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>number_customer_service_calls</td>\n",
       "      <td>0.115694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_eve_charge</td>\n",
       "      <td>0.055175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_eve_minutes</td>\n",
       "      <td>0.047867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_intl_minutes</td>\n",
       "      <td>0.041981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_intl_calls</td>\n",
       "      <td>0.041646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number_vmail_messages</td>\n",
       "      <td>0.040985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_intl_charge</td>\n",
       "      <td>0.035378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           column  feature_imp\n",
       "2               total_day_minutes     0.231654\n",
       "4                total_day_charge     0.168910\n",
       "14                 int_plan_coded     0.134480\n",
       "13  number_customer_service_calls     0.115694\n",
       "7                total_eve_charge     0.055175\n",
       "5               total_eve_minutes     0.047867\n",
       "10             total_intl_minutes     0.041981\n",
       "11               total_intl_calls     0.041646\n",
       "1           number_vmail_messages     0.040985\n",
       "12              total_intl_charge     0.035378"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=pd.DataFrame(columns=['column','feature_imp'])\n",
    "t1.column, t1.feature_imp= train_cols, clf.feature_importances_\n",
    "t1.sort_values(by='feature_imp',ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv('churn_dataset_test.csv')\n",
    "orig_cols= test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "performing the preprocessing steps on test data as well\n",
    "\"\"\"\n",
    "test= test.fillna(0)\n",
    "\"\"\"\n",
    "Encoding the binary variables for modeling purposes\n",
    "\"\"\"\n",
    "\n",
    "test['int_plan_coded']=np.where(test.international_plan=='yes',1,0)\n",
    "test['vm_plan_coded']=np.where(test.voice_mail_plan=='yes',1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making predictions\n",
    "\"\"\"\n",
    "pred_prob=clf.predict_proba(test[train_cols])\n",
    "pred= np.where(pred_prob>0.5 , 1,0)\n",
    "y_pred= [np.argmax(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assigning the test labels to the test data and saving the data with original columns \n",
    "\"\"\"\n",
    "test['churn']=y_pred\n",
    "test['churn']=np.where(test.churn==1, 'yes','no')\n",
    "test[orig_cols].to_csv('churn_dataset_test_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.896\n",
       "yes    0.104\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['churn'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
